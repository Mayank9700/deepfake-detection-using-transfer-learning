# deepfake-detection-using-transfer-learning
With the rapid evolution of digital media in today's society, something called "deepfake" technology is causing a big problem. Deepfakes are fake videos or sounds that look and sound real. They make it hard to know if what you see and hear is true. 

This study examines how pre-trained Keras models perform in detecting deepfake faces. We compare the performance of VGG16, ResNet50, MobileNet, InceptionV3, and DenseNet169 models using both feature extraction and fine-tuning approaches. Our analysis focuses on accuracy, validation accuracy, and potential trade-offs between model complexity and efficiency. 

In conclusion, the comparative analysis of various pre-trained models, including VGG16, ResNet50, DenseNet169, EfficientNetB0, InceptionV3, and MobileNet, reveals that fine-tuning generally enhances model performance over feature extraction. Notably, MobileNet, DenseNet169, and VGG16 exhibit the highest validation accuracies, with fine-tuning yielding significant improvements in generalization and accuracy. These findings underscore the effectiveness of fine-tuning pre-trained models for deepfake detection, suggesting that models like MobileNet, DenseNet169, and VGG16 are particularly well-suited for this task.
